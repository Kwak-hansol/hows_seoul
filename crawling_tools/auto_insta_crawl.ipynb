{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f639eb-ce3c-4709-8382-5a30a835ca11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27 divs with class '_aagv' on this scroll.\n",
      "Found 28 divs with class '_aagv' on this scroll.\n",
      "Found 30 divs with class '_aagv' on this scroll.\n",
      "크롤링 데이터가 엑셀 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "\n",
    "# 로그인 정보 하드코딩\n",
    "USERNAME = 'loextasy@naver.com'  # 여기에 Instagram 사용자 이름을 입력하세요\n",
    "PASSWORD = 'v912803V!!!'  # 여기에 Instagram 비밀번호를 입력하세요\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Chrome 드라이버를 설정하고 반환합니다.\"\"\"\n",
    "    chrome_driver_path = 'C:\\\\chromedriver-win64\\\\chromedriver.exe'\n",
    "    service = Service(chrome_driver_path)\n",
    "\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    return driver\n",
    "\n",
    "def login_instagram(driver):\n",
    "    \"\"\"Instagram에 로그인합니다.\"\"\"\n",
    "    driver.get('https://www.instagram.com/accounts/login/')\n",
    "    time.sleep(2)\n",
    "\n",
    "    username_input = driver.find_element(By.NAME, 'username')\n",
    "    password_input = driver.find_element(By.NAME, 'password')\n",
    "    login_button = driver.find_element(By.XPATH, '//button[@type=\"submit\"]')\n",
    "\n",
    "    username_input.send_keys(USERNAME)\n",
    "    password_input.send_keys(PASSWORD)\n",
    "    login_button.click()\n",
    "\n",
    "    time.sleep(5)  # 로그인 후 대기\n",
    "\n",
    "def crawl_instagram(driver, search_query):\n",
    "    \"\"\"주어진 검색어로 Instagram에서 데이터를 크롤링합니다.\"\"\"\n",
    "    search_query_encoded = urllib.parse.quote(search_query)\n",
    "    search_url = f'https://www.instagram.com/explore/tags/{search_query_encoded}/'\n",
    "    \n",
    "    driver.get(search_url)\n",
    "    time.sleep(30)  # 페이지가 완전히 로드될 때까지 대기\n",
    "\n",
    "    SCROLL_PAUSE_TIME = 1\n",
    "    alt_texts = []\n",
    "\n",
    "    last_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    while True:\n",
    "        pagestring = driver.page_source\n",
    "        bs = BeautifulSoup(pagestring, 'lxml')\n",
    "        \n",
    "        post_divs = bs.find_all('div', {'class': '_aagv'})\n",
    "        \n",
    "        for div in post_divs:\n",
    "            img_tags = div.find_all('img')\n",
    "            for img in img_tags:\n",
    "                alt_text = img.get('alt')\n",
    "                if alt_text:\n",
    "                    alt_texts.append(alt_text)\n",
    "        \n",
    "        if post_divs:\n",
    "            print(f\"Found {len(post_divs)} divs with class '_aagv' on this scroll.\")\n",
    "        \n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "        \n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return alt_texts\n",
    "\n",
    "def save_to_excel(data_dict, current_time):\n",
    "    \"\"\"크롤링한 데이터를 엑셀 파일로 저장합니다.\"\"\"\n",
    "    all_data = []\n",
    "    for search_query, alt_texts in data_dict.items():\n",
    "        if alt_texts:\n",
    "            df = pd.DataFrame({\n",
    "                \"검색어\": [search_query] * len(alt_texts),\n",
    "                \"검색결과\": alt_texts\n",
    "            })\n",
    "            all_data.append(df)\n",
    "\n",
    "    if all_data:\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        final_df.to_excel(f\"인스타그램크롤링_{current_time}.xlsx\", index=False)\n",
    "        print(\"크롤링 데이터가 엑셀 파일로 저장되었습니다.\")\n",
    "    else:\n",
    "        print(\"No data found.\")\n",
    "\n",
    "def main():\n",
    "    current_time = datetime.now().strftime('%y-%m-%d')\n",
    "    \n",
    "    # 검색어 리스트 입력\n",
    "    search_queries = [\n",
    "    # 발달상권\n",
    "    \"성수카페거리\",\n",
    "    \"가로수길\",\n",
    "    \"북촌한옥마을\",\n",
    "    \"인사동·익선동\",\n",
    "    \"광장(전통)시장\",\n",
    "    \"압구정로데오거리\",\n",
    "    \n",
    "    # 인구밀집지역\n",
    "    \"홍대입구역(2호선)\",\n",
    "    \"이태원역\",\n",
    "    \"강남역\",\n",
    "    \"서울식물원·마곡나루역\",\n",
    "    \n",
    "    # 관광특구\n",
    "    \"동대문 관광특구\",\n",
    "    \"명동 관광특구\",\n",
    "    \"잠실 관광특구\",\n",
    "    \"종로·청계 관광특구\",\n",
    "    \n",
    "    # 고궁 문화유산\n",
    "    \"경복궁\",\n",
    "    \"광화문·덕수궁\",\n",
    "    \"창덕궁 종묘\",\n",
    "    \"보신각\",\n",
    "    \n",
    "    # 공원\n",
    "    \"반포한강공원\",\n",
    "    \"고척돔\",\n",
    "    \"남산공원\",\n",
    "    \"잠실종합운동장\",\n",
    "    \"서울숲공원\",\n",
    "    \"국립중앙박물관·용산가족공원\",\n",
    "    \"서울대공원\"\n",
    "    ]\n",
    "\n",
    "    driver = setup_driver()\n",
    "    login_instagram(driver)\n",
    "    \n",
    "    data_dict = {}\n",
    "    for search_query in search_queries:\n",
    "        alt_texts = crawl_instagram(driver, search_query)\n",
    "        data_dict[search_query] = alt_texts\n",
    "    \n",
    "    save_to_excel(data_dict, current_time)\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b98c7d-d5fc-4299-9658-522debc07f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 divs with class '_aagv' on this scroll.\n",
      "Found 7 divs with class '_aagv' on this scroll.\n",
      "Found 28 divs with class '_aagv' on this scroll.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from datetime import datetime\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import re\n",
    "\n",
    "# 로그인 정보 하드코딩\n",
    "USERNAME = 'loextasy@naver.com'  # 여기에 Instagram 사용자 이름을 입력하세요\n",
    "PASSWORD = 'v912803V!!!'  # 여기에 Instagram 비밀번호를 입력하세요\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Chrome 드라이버를 설정하고 반환합니다.\"\"\"\n",
    "    chrome_driver_path = 'C:\\\\chromedriver-win64\\\\chromedriver.exe'\n",
    "    service = Service(chrome_driver_path)\n",
    "\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-notifications\")\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    return driver\n",
    "\n",
    "def login_instagram(driver):\n",
    "    \"\"\"Instagram에 로그인합니다.\"\"\"\n",
    "    driver.get('https://www.instagram.com/accounts/login/')\n",
    "    time.sleep(2)\n",
    "\n",
    "    username_input = driver.find_element(By.NAME, 'username')\n",
    "    password_input = driver.find_element(By.NAME, 'password')\n",
    "    login_button = driver.find_element(By.XPATH, '//button[@type=\"submit\"]')\n",
    "\n",
    "    username_input.send_keys(USERNAME)\n",
    "    password_input.send_keys(PASSWORD)\n",
    "    login_button.click()\n",
    "\n",
    "    time.sleep(5)  # 로그인 후 대기\n",
    "\n",
    "def remove_parentheses(query):\n",
    "    \"\"\"검색어에서 괄호와 괄호 안의 내용을 제거합니다.\"\"\"\n",
    "    return re.sub(r'\\(.*?\\)', '', query).strip()\n",
    "\n",
    "def crawl_instagram(driver, search_query):\n",
    "    \"\"\"주어진 검색어로 Instagram에서 데이터를 크롤링합니다.\"\"\"\n",
    "    search_query_encoded = urllib.parse.quote(remove_parentheses(search_query).replace(' ', ''))\n",
    "    search_url = f'https://www.instagram.com/explore/tags/{search_query_encoded}/'\n",
    "    \n",
    "    driver.get(search_url)\n",
    "    time.sleep(30)  # 페이지가 완전히 로드될 때까지 대기\n",
    "\n",
    "    SCROLL_PAUSE_TIME = 1\n",
    "    alt_texts = []\n",
    "\n",
    "    last_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    while True:\n",
    "        pagestring = driver.page_source\n",
    "        bs = BeautifulSoup(pagestring, 'lxml')\n",
    "        \n",
    "        post_divs = bs.find_all('div', {'class': '_aagv'})\n",
    "        \n",
    "        for div in post_divs:\n",
    "            img_tags = div.find_all('img')\n",
    "            for img in img_tags:\n",
    "                alt_text = img.get('alt')\n",
    "                if alt_text:\n",
    "                    alt_texts.append(alt_text)\n",
    "        \n",
    "        if post_divs:\n",
    "            print(f\"Found {len(post_divs)} divs with class '_aagv' on this scroll.\")\n",
    "        \n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "        \n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    return alt_texts\n",
    "\n",
    "def save_to_excel(data_dict, current_time):\n",
    "    \"\"\"크롤링한 데이터를 엑셀 파일로 저장합니다.\"\"\"\n",
    "    all_data = []\n",
    "    for search_query, alt_texts in data_dict.items():\n",
    "        if alt_texts:\n",
    "            df = pd.DataFrame({\n",
    "                \"검색어\": [search_query] * len(alt_texts),\n",
    "                \"검색결과\": alt_texts\n",
    "            })\n",
    "            all_data.append(df)\n",
    "\n",
    "    if all_data:\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        final_df.to_excel(f\"인스타그램크롤링_{current_time}.xlsx\", index=False)\n",
    "        print(\"크롤링 데이터가 엑셀 파일로 저장되었습니다.\")\n",
    "    else:\n",
    "        print(\"No data found.\")\n",
    "\n",
    "def main():\n",
    "    current_time = datetime.now().strftime('%y-%m-%d')\n",
    "    \n",
    "    # 검색어 리스트 입력\n",
    "    search_queries = [\n",
    "        # 발달상권\n",
    "        \"성수카페거리\",\n",
    "        \"가로수길\",\n",
    "        \"북촌한옥마을\",\n",
    "        \"인사동·익선동\",\n",
    "        \"광장(전통)시장\",\n",
    "        \"압구정로데오거리\",\n",
    "        \n",
    "        # 인구밀집지역\n",
    "        \"홍대입구역(2호선)\",\n",
    "        \"이태원역\",\n",
    "        \"강남역\",\n",
    "        \"서울식물원·마곡나루역\",\n",
    "        \n",
    "        # 관광특구\n",
    "        \"동대문 관광특구\",\n",
    "        \"명동 관광특구\",\n",
    "        \"잠실 관광특구\",\n",
    "        \"종로·청계 관광특구\",\n",
    "        \n",
    "        # 고궁 문화유산\n",
    "        \"경복궁\",\n",
    "        \"광화문·덕수궁\",\n",
    "        \"창덕궁·종묘\",\n",
    "        \"보신각\",\n",
    "        \n",
    "        # 공원\n",
    "        \"반포한강공원\",\n",
    "        \"고척돔\",\n",
    "        \"남산공원\",\n",
    "        \"잠실종합운동장\",\n",
    "        \"서울숲공원\",\n",
    "        \"국립중앙박물관·용산가족공원\",\n",
    "        \"서울대공원\"\n",
    "    ]\n",
    "\n",
    "    driver = setup_driver()\n",
    "    login_instagram(driver)\n",
    "    \n",
    "    data_dict = {}\n",
    "    for search_query in search_queries:\n",
    "        # 검색어에 '·'가 포함된 경우, 이를 기준으로 분할\n",
    "        if '·' in search_query:\n",
    "            sub_queries = search_query.split('·')\n",
    "            combined_results = []\n",
    "            for sub_query in sub_queries:\n",
    "                alt_texts = crawl_instagram(driver, sub_query.strip())\n",
    "                combined_results.extend(alt_texts)\n",
    "            data_dict[search_query] = combined_results\n",
    "        else:\n",
    "            alt_texts = crawl_instagram(driver, search_query)\n",
    "            data_dict[search_query] = alt_texts\n",
    "    \n",
    "    save_to_excel(data_dict, current_time)\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
